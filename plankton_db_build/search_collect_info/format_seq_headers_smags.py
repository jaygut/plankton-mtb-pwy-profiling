#!/home/VLIZ2000/jayson.gutierrez/anaconda3/envs/bioinformatics/bin/python

"""Processing the SMAGs DB published by Delmont et.al. 2020 (https://www.biorxiv.org/content/10.1101/2020.10.15.341214v2):  

Excerpt from abstract:
We used 280 billion Tara Oceans metagenomic reads from polar, temperate, and tropical sunlit oceans to reconstruct and manually curate more than 700 abundant 
and widespread eukaryotic environmental genomes ranging from 10 Mbp to 1.3 Gbp. This genomic resource covers a wide range of poorly characterized eukaryotic 
lineages that complement long-standing contributions from culture collections while better representing plankton in the upper layer of the oceans.  

The DB is accessible from TARA Oceans repository (https://www.genoscope.cns.fr/tara/).  

The goal here is:
To properly format this protein seq DB in a way that one can use it with humann to profile environmental samples at the metabolic pathway level. To achieve this, we have to: 

    1. Annotate the target sequence against UniRef90_2020-2.
    2. Create a .dmnd DB out of this newly created .faa file of UniRef90 annotated sequences.
    
Jayson Gutierrez: 1/2/2021
"""

from subprocess import Popen, call, STDOUT, PIPE
import os
import shutil
import pandas as pd
import json
import glob
import re
import gzip
import sys
import csv
import time
import io
import pathlib

import Bio.SeqIO as bioseqio
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
#from Bio.Alphabet import IUPAC
from Bio import Entrez

def extract_annots_from_dmnd_output(sorted_annotat_files):
    '''Function to loop over annotation files (target-query hits) generated by Diamond against UniRef90'''
    
    #Loop over all the annotation results files
    annot_res_df_cont = []
    for af in sorted_annotat_files:
        with open(af,"r") as annot_file:
            lines = annot_file.readlines()

        col_names = [s.replace(" ","_") for s in lines[2].split(":")[1].strip().split(', ')]

        #Fetch entries
        annot_res = []
        for l in lines[3:]:
            annot_res.append(l.strip().split('\t'))

        #Cast raw data into a DF
        annot_res_df = pd.DataFrame(data=annot_res,columns=col_names)

        #Convert fields to numeric and cast data as new DF
        new_annot_res_df = annot_res_df[new_col_names].apply(pd.to_numeric)
        new_annot_res_df["Subject_ID"] = annot_res_df["Subject_ID"]
        new_annot_res_df.index = annot_res_df["Query_ID"]
        #Stack up DFs
        annot_res_df_cont.append(new_annot_res_df)

    #Create full df of annotations
    annot_all_results_df = pd.concat(annot_res_df_cont)

    #Iterate over DF rows to generate a new col with the definitive UniRef90-based annotation for a given seq in the SMAGs DB
    new_uniref_annots = []
    for df in annot_all_results_df.iterrows():
        #Fetch original fields from header
        origanot,seql,maintxnl,ncbitxid,extratax = df[0].split("|")
        #Fetch UniRef90 annotation derived from diamond run
        uniref_annot = df[1]['Subject_ID']
        new_uniref_annots.append("{}|{}|{}__{}|{}".format(uniref_annot,seql,maintxnl,ncbitxid,extratax))
        
    annot_all_results_df["UniRef90_Annotation"] = new_uniref_annots

    return annot_all_results_df

def pull_out_seq_matches_reformat(annot_all_results_df,sorted_seq_hits_files,SMAGs_uniref90_annotated_fid):
    '''Function to pull out seq matches for the .faa files generated by Diamond when ran against UniRef90'''
    
    #Now loop over each subset of annotated seqs and dump them into a file with appropriate header
    #A list to store non-redundant headers
    new_header_cont = []
    for seqs_subset in sorted_seq_hits_files:
        #Now, let's iterate over the seqs with hits on UniRef90
        with open(seqs_subset,"r") as handle:
            for (i,record) in enumerate(bioseqio.parse(handle, "fasta")):
                try:
                    new_header = annot_all_results_df.loc[record.description]["UniRef90_Annotation"]
                    #Make sure that X is not part of the seq and that the seq has not been previously dumped into the fasta file
                    if("X" not in record.seq):
                        if(new_header in new_header_cont):
                            pass
                        else:
                            #Update list
                            new_header_cont.append(new_header)
                            #Update header
                            record.id = ''
                            record.name = ''
                            record.description = ''
                            record.id = new_header
                            #Dump record into file
                            with open(SMAGs_uniref90_annotated_fid, "a") as output_handle:
                                bioseqio.write(record, output_handle, "fasta")
                except:
                    pass


if __name__ == "__main__":

    #Set $WORK_DIR
    data_dir = '/home/VLIZ2000/jayson.gutierrez/meta_omics_data/marine_databases/TARA_Oceans/TARA_SMAGs/'
    #data_dir = '/kyukon/data/gent/vo/001/gvo00125/vsc43582/Bioinformatics/Annotation/Data/TARA_SMAGs/'
    
    #Numeric columns in output files
    new_col_names = ['Percentage_of_identical_matches', 'Alignment_length', 'Number_of_mismatches', 'Number_of_gap_openings',
                    'Start_of_alignment_in_query', 'End_of_alignment_in_query','Start_of_alignment_in_subject', 
                    'End_of_alignment_in_subject','Expected_value', 'Bit_score']

    #List all tables containing annotation info (seq alignment scores against UniRef90)
    annotat_files = glob.glob(os.path.join(data_dir,'SMAGs_filtered_chunk_annots_*.tsv'))
    sorted_annotat_files = sorted(annotat_files, key = lambda s: int(os.path.basename(s).split("_")[-1].replace(".tsv","")))
    #Extracting information cast in a DF
    print("Initialize extracting annotations")
    annot_all_results_df = extract_annots_from_dmnd_output(sorted_annotat_files)
    print("Extracting annotations: DONE!")
    print("--------------------------------------------")
    #Set input/output files for annotated seqs
    seq_hits_files = glob.glob(os.path.join(data_dir,'SMAGs_filtered_chunk_annot_seqs_*.faa'))
    sorted_seq_hits_files = sorted(seq_hits_files, key = lambda s: int(os.path.basename(s).split("_")[-1].replace(".faa","")))
    SMAGs_uniref90_annotated_fid = os.path.join(data_dir,"SMAGs_UniRef90_Annotated.faa")
    #Reformat seq headers in a way that can be read by humann: dumping seqs into a fasta file
    print("Initialize reformatting of headers for annotated seqs")
    pull_out_seq_matches_reformat(annot_all_results_df,sorted_seq_hits_files,SMAGs_uniref90_annotated_fid)
    print("Reformatting of headers for annotated seqs: DONE!")
    
